# üöÄ C√ÅC B∆Ø·ªöC TI·∫æP THEO SAU KHI TRAIN MODEL

B·∫°n ƒë√£ train xong 3 configs v√† c√≥ **model t·ªët nh·∫•t: efficientnet_b0_optimized (98.67% accuracy)**.

D∆∞·ªõi ƒë√¢y l√† c√°c b∆∞·ªõc MLOps ti·∫øp theo ƒë·ªÉ deploy v√† s·ª≠ d·ª•ng model.

---

## üìä B∆Ø·ªöC 1: ƒê√ÅNH GI√Å CHI TI·∫æT MODEL (ƒêang ch·∫°y...)

```powershell
python src/evaluate.py --model-path models/efficientnet_b0_optimized/best_model.pth --val-dir validation
```

**K·∫øt qu·∫£ t·∫°o ra:**
- `evaluation_results/confusion_matrix.png` - Ma tr·∫≠n nh·∫ßm l·∫´n
- `evaluation_results/per_class_accuracy.png` - Accuracy t·ª´ng class
- `evaluation_results/classification_report.txt` - Precision, Recall, F1
- `evaluation_results/metrics.json` - C√°c metrics t·ªïng h·ª£p

**ƒê·ªÉ l√†m g√¨:**
- Ph√¢n t√≠ch class n√†o model d·ª± ƒëo√°n t·ªët/k√©m
- T√¨m patterns sai (class n√†o th∆∞·ªùng b·ªã nh·∫ßm v·ªõi class n√†o)
- Quy·∫øt ƒë·ªãnh c√≥ c·∫ßn thu th·∫≠p th√™m data cho class y·∫øu kh√¥ng

---

## üîå B∆Ø·ªöC 2: TEST API PREDICTION

### 2.1. Start API Server

**Terminal 1** (PowerShell):
```powershell
python start_api.py
```

Ho·∫∑c v·ªõi custom model:
```powershell
$env:MODEL_PATH="models/efficientnet_b0_optimized/best_model.pth"
$env:MODEL_NAME="efficientnet_b0"
python -m uvicorn api.app:app --host 0.0.0.0 --port 8000
```

**Ki·ªÉm tra:** M·ªü http://localhost:8000/docs (Swagger UI)

### 2.2. Test Predictions

**Terminal 2** (PowerShell):
```powershell
python test_api.py
```

Ho·∫∑c test th·ªß c√¥ng v·ªõi curl:
```powershell
# Health check
curl http://localhost:8000/health

# Predict single image
curl -X POST "http://localhost:8000/predict" -F "file=@validation/healthy/healthy_001.jpg"

# Model info
curl http://localhost:8000/model/info
```

**K·∫øt qu·∫£:**
- Xem inference time (ms/request)
- Ki·ªÉm tra accuracy tr√™n validation set
- Test v·ªõi ·∫£nh th·∫≠t t·ª´ user

---

## üê≥ B∆Ø·ªöC 3: DEPLOY V·ªöI DOCKER

### 3.1. Build Docker Image

```powershell
# Build API image
docker build -f docker/Dockerfile.api -t rice-disease-api:latest .

# Check image
docker images | Select-String rice-disease
```

### 3.2. Run Container

```powershell
# Run API container
docker run -d `
  --name rice-api `
  -p 8000:8000 `
  -v ${PWD}/models:/app/models `
  -e MODEL_PATH=/app/models/efficientnet_b0_optimized/best_model.pth `
  -e MODEL_NAME=efficientnet_b0 `
  rice-disease-api:latest

# Check logs
docker logs -f rice-api

# Test
curl http://localhost:8000/health
```

### 3.3. Docker Compose (To√†n b·ªô stack)

```powershell
# Start all services (API + MLflow + Airflow)
docker-compose up -d

# Check status
docker-compose ps

# View logs
docker-compose logs -f api

# Stop all
docker-compose down
```

**Services:**
- API: http://localhost:8000
- MLflow: http://localhost:5000
- Airflow: http://localhost:8080 (admin/admin)

---

## ‚öôÔ∏è B∆Ø·ªöC 4: SETUP AIRFLOW PIPELINES

### 4.1. Start Airflow

```powershell
# Initialize database (first time only)
docker-compose run airflow-webserver airflow db init

# Create admin user
docker-compose run airflow-webserver airflow users create `
  --username admin `
  --password admin `
  --firstname Admin `
  --lastname User `
  --role Admin `
  --email admin@example.com

# Start all Airflow services
docker-compose up -d
```

### 4.2. Access Airflow UI

M·ªü http://localhost:8080
- Username: `admin`
- Password: `admin`

### 4.3. Enable DAGs

**2 DAGs c√≥ s·∫µn:**

1. **`training_pipeline`** - T·ª± ƒë·ªông retrain model
   - Schedule: H√†ng tu·∫ßn (Ch·ªß Nh·∫≠t 2AM)
   - Tasks:
     - Prepare data
     - Train model
     - Evaluate model
     - Compare v·ªõi model c≈©
     - Deploy n·∫øu t·ªët h∆°n

2. **`deployment_pipeline`** - Deploy model m·ªõi
   - Trigger th·ªß c√¥ng ho·∫∑c sau training
   - Tasks:
     - Validate model
     - Build Docker image
     - Deploy to production
     - Health check

**Trong UI:**
- Click toggle b√™n c·∫°nh DAG name ƒë·ªÉ enable
- Click DAG name ‚Üí Trigger DAG ƒë·ªÉ ch·∫°y th·ªß c√¥ng

---

## üìà B∆Ø·ªöC 5: MONITORING V√Ä MLFLOW

### 5.1. MLflow Model Registry

```python
import mlflow

mlflow.set_tracking_uri("http://localhost:5000")

# Register best model
client = mlflow.tracking.MlflowClient()
model_uri = "runs://4b8e6057500b4b03bef452bac0c212dd/model"

# Create registered model
client.create_registered_model(
    name="rice-disease-classifier",
    description="Production model for rice disease classification"
)

# Add version
mv = client.create_model_version(
    name="rice-disease-classifier",
    source=model_uri,
    run_id="4b8e6057500b4b03bef452bac0c212dd"
)

# Promote to production
client.transition_model_version_stage(
    name="rice-disease-classifier",
    version=mv.version,
    stage="Production"
)
```

### 5.2. View Experiments

```powershell
# Xem t·∫•t c·∫£ runs
python src/view_all_results.py

# T√¨m run c·ª• th·ªÉ
python src/find_run.py efficientnet_b0_optimized_20251214_012804
```

**MLflow UI:** http://localhost:5000
- Compare runs
- Visualize metrics
- Download models
- Track experiments

### 5.3. Monitor API Performance

```python
# View Prometheus metrics
curl http://localhost:8000/metrics
```

**Metrics tracked:**
- `inference_requests_total` - S·ªë request
- `inference_latency_seconds` - Latency
- `predictions_by_class` - Predictions per class

---

## üß™ B∆Ø·ªöC 6: A/B TESTING (Optional)

Deploy 2 models c√πng l√∫c v√† so s√°nh:

```python
# deploy_ab_test.py
from fastapi import FastAPI
import random

app = FastAPI()

# Load 2 models
model_a = load_model("models/efficientnet_b0_optimized/best_model.pth")
model_b = load_model("models/mobilenetv3_large/best_model.pth")

@app.post("/predict")
async def predict(file: UploadFile):
    # Route 50% traffic to each model
    model = model_a if random.random() < 0.5 else model_b
    result = model.predict(file)
    result["model_version"] = "A" if model == model_a else "B"
    return result
```

**Track results:**
- So s√°nh accuracy trong production
- So s√°nh inference time
- Ch·ªçn model t·ªët h∆°n

---

## üéØ B∆Ø·ªöC 7: CONTINUOUS TRAINING

Setup t·ª± ƒë·ªông retrain khi c√≥ data m·ªõi:

1. **Th√™m data m·ªõi v√†o `train/` v√† `validation/`**

2. **Trigger Airflow DAG:**
   ```powershell
   # Trigger via CLI
   docker-compose exec airflow-webserver airflow dags trigger training_pipeline

   # Ho·∫∑c trong Airflow UI
   ```

3. **Model t·ª± ƒë·ªông:**
   - Train v·ªõi data m·ªõi
   - Evaluate v√† compare
   - Deploy n·∫øu t·ªët h∆°n model c≈©

---

## üìù CHECKLIST ƒê·ªÇ DEPLOY L√äN PRODUCTION

- [ ] **Evaluation** - Xem confusion matrix, ph√¢n t√≠ch l·ªói
- [ ] **API Testing** - Test v·ªõi nhi·ªÅu ·∫£nh, measure latency
- [ ] **Docker** - Build v√† test container locally
- [ ] **MLflow Registry** - Register model v·ªõi version
- [ ] **Airflow** - Setup automatic retraining schedule
- [ ] **Monitoring** - Setup alerts cho accuracy drop
- [ ] **Documentation** - Document API endpoints, model behavior
- [ ] **Security** - Add authentication, rate limiting
- [ ] **Cloud Deployment** - Deploy to AWS/GCP/Azure
- [ ] **CI/CD** - Setup GitHub Actions cho auto-deploy

---

## üöÄ QUICK START COMMANDS

```powershell
# 1. Evaluate model (ƒëang ch·∫°y)
python src/evaluate.py --model-path models/efficientnet_b0_optimized/best_model.pth

# 2. Start API
python start_api.py

# 3. Test API (terminal kh√°c)
python test_api.py

# 4. Docker
docker-compose up -d

# 5. View results
python src/view_all_results.py

# 6. MLflow UI
# M·ªü http://localhost:5000

# 7. Airflow UI
# M·ªü http://localhost:8080 (admin/admin)
```

---

B·∫°n mu·ªën b·∫Øt ƒë·∫ßu b∆∞·ªõc n√†o? T√¥i s·∫Ω h∆∞·ªõng d·∫´n chi ti·∫øt!
